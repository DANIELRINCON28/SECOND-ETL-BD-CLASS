{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SECOND ETL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3-ahySyd15E",
        "outputId": "6329d50f-a0fd-43a8-ed79-48ef501291f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.12.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (2.9.0.post0)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (18.1.0)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil) (1.17.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas pymongo python-dateutil pyarrow pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWdC9Hwfc9Qh",
        "outputId": "397ee4b8-3674-4b88-ba79-35921bd22de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando y preprocesando datos desde CSV...\n",
            "Datos preprocesados: 24413 filas\n",
            "Cargando datos a MongoDB...\n",
            "Error de conexión a MongoDB: localhost:27017: [Errno 111] Connection refused (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: <TopologyDescription id: 68197b4b8cae37b3e73a9705, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [Errno 111] Connection refused (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')>]>\n",
            "Cargando datos a SQLite...\n",
            "Datos cargados en SQLite: alquileres.db.clientes_procesados (24413 filas)\n",
            "Cargando datos a archivo Parquet...\n",
            "Datos guardados en archivo Parquet: clientes_procesados.parquet (24413 filas)\n",
            "Leyendo archivo Parquet con Spark...\n",
            "Primeras 5 filas del archivo Parquet:\n",
            "+--------------+-----------------+--------------------+---------------+--------------------+-----------------+----------------+---------------------------+-------+----------------------+\n",
            "|codigo_usuario|           nombre|           direccion|       telefono|  correo_electronico|fecha_de_alquiler|fecha_de_entrega|nombre_de_la_pelicula/video|formato|duracion_alquiler_dias|\n",
            "+--------------+-----------------+--------------------+---------------+--------------------+-----------------+----------------+---------------------------+-------+----------------------+\n",
            "|       U000001|    Stacy Bradley|67188 Miranda Cov...|+1-401-096-0674|   shaun81@yahoo.com|       2024-08-30|      2024-12-17|                   Few hope|    DVD|                   109|\n",
            "|       U000002|    Anthony Bryan|5336 Samantha Via...|+1-046-616-5637| ginawhite@heath.net|       2022-05-10|      2023-08-05|                       Food|    VHS|                   452|\n",
            "|       U000003|   Nichole Cooper|57122 Barber Pine...|+1-139-320-7865|brian27@king-gree...|       2023-04-07|      2024-01-11|       Radio recent similar|    VHS|                   279|\n",
            "|       U000004|  Joseph Guerrero|0599 Brad Flat Ap...|+1-157-868-6392|  samuel07@gmail.com|       2022-10-17|      2023-02-20|          Anything official|    DVD|                   126|\n",
            "|       U000005|Patricia Phillips|86956 Estrada Vie...|+1-805-257-0851|tammy95@bailey-le...|       2023-09-28|      2024-01-10|               Sing product|Blu-ray|                   104|\n",
            "+--------------+-----------------+--------------------+---------------+--------------------+-----------------+----------------+---------------------------+-------+----------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd \n",
        "import sqlite3\n",
        "from pymongo import MongoClient\n",
        "from pymongo.errors import ConnectionFailure\n",
        "import re\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "import pyarrow.parquet as pq\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Función para cargar y preprocesar datos desde CSV\n",
        "def cargar_y_preprocesar_datos(ruta_archivo):\n",
        "    print(\"Cargando y preprocesando datos desde CSV...\")\n",
        "    try:\n",
        "        df = pd.read_csv(ruta_archivo, encoding='utf-8', dtype=str)\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el CSV: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Manejar valores faltantes\n",
        "    def validar_correo(correo):\n",
        "        if pd.isna(correo) or not re.match(r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$', correo):\n",
        "            return 'sin_correo@desconocido.com'\n",
        "        return correo.strip()\n",
        "\n",
        "    df['correo_electronico'] = df['correo_electronico'].apply(validar_correo)\n",
        "\n",
        "    def estandarizar_telefono(telefono):\n",
        "        if pd.isna(telefono) or telefono.strip() == '':\n",
        "            return 'Desconocido'\n",
        "        telefono = re.sub(r'[^\\d+-]', '', telefono)\n",
        "        digitos = re.findall(r'\\d', telefono)\n",
        "        if len(digitos) >= 10:\n",
        "            return f\"+1-{''.join(digitos[-10:-7])}-{''.join(digitos[-7:-4])}-{''.join(digitos[-4:])}\"\n",
        "        return 'Desconocido'\n",
        "\n",
        "    df['telefono'] = df['telefono'].apply(estandarizar_telefono)\n",
        "\n",
        "    df = df.fillna({\n",
        "        'nombre': 'Desconocido',\n",
        "        'direccion': 'Desconocida',\n",
        "        'nombre_de_la_pelicula/video': 'Desconocida',\n",
        "        'formato': 'Desconocido'\n",
        "    })\n",
        "\n",
        "    # Normalizar direcciones\n",
        "    def normalizar_direccion(direccion):\n",
        "        if pd.isna(direccion) or direccion.strip() == '' or direccion == 'Desconocida':\n",
        "            return 'Desconocida'\n",
        "        direccion = ' '.join(direccion.lower().split())\n",
        "        reemplazos = {\n",
        "            r'\\bcalle\\b': 'C.',\n",
        "            r'\\bavenida\\b': 'Av.',\n",
        "            r'\\bnumero\\b': 'No.',\n",
        "            r'\\bcolonia\\b': 'Col.',\n",
        "            r'\\bcarretera\\b': 'Carr.',\n",
        "            r'\\bboulevard\\b': 'Blvd.'\n",
        "        }\n",
        "        for patron, reemplazo in reemplazos.items():\n",
        "            direccion = re.sub(patron, reemplazo, direccion)\n",
        "        direccion = ' '.join(word.capitalize() for word in direccion.split())\n",
        "        direccion = re.sub(r'[^\\w\\s\\.\\,]', '', direccion)\n",
        "        return direccion\n",
        "\n",
        "    df['direccion'] = df['direccion'].apply(normalizar_direccion)\n",
        "\n",
        "    # Corregir fechas inconsistentes\n",
        "    def parsear_fecha(fecha_str):\n",
        "        if pd.isna(fecha_str) or fecha_str.strip() == '':\n",
        "            return None\n",
        "        try:\n",
        "            fecha = parse(fecha_str, fuzzy=True, dayfirst=True)\n",
        "            if 2000 <= fecha.year <= 2025:\n",
        "                return fecha.strftime('%Y-%m-%d')\n",
        "            return None\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    df['fecha_de_alquiler'] = df['fecha_de_alquiler'].apply(parsear_fecha)\n",
        "    df['fecha_de_entrega'] = df['fecha_de_entrega'].apply(parsear_fecha)\n",
        "    df = df.dropna(subset=['fecha_de_alquiler', 'fecha_de_entrega'])\n",
        "\n",
        "    # Calcular duración del alquiler\n",
        "    df['duracion_alquiler_dias'] = (\n",
        "        pd.to_datetime(df['fecha_de_entrega']) - pd.to_datetime(df['fecha_de_alquiler'])\n",
        "    ).dt.days\n",
        "    df = df[df['duracion_alquiler_dias'] >= 0]\n",
        "\n",
        "    print(f\"Datos preprocesados: {len(df)} filas\")\n",
        "    return df\n",
        "\n",
        "# Carga en MongoDB\n",
        "def cargar_a_mongodb(df, db_name='alquileres', collection_name='clientes'):\n",
        "    print(\"Cargando datos a MongoDB...\")\n",
        "    try:\n",
        "        client = MongoClient('mongodb://localhost:27017/')\n",
        "        db = client[db_name]\n",
        "        collection = db[collection_name]\n",
        "        collection.drop()  # Limpiar colección existente\n",
        "        records = df.to_dict('records')\n",
        "        collection.insert_many(records)\n",
        "        print(f\"Datos cargados en MongoDB: {db_name}.{collection_name} ({len(records)} documentos)\")\n",
        "        client.close()\n",
        "    except ConnectionFailure as e:\n",
        "        print(f\"Error de conexión a MongoDB: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar en MongoDB: {e}\")\n",
        "\n",
        "# Carga en SQLite (Data Warehouse ligero)\n",
        "def cargar_a_sqlite(df, db_name='alquileres.db', table_name='clientes_procesados'):\n",
        "    print(\"Cargando datos a SQLite...\")\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_name)\n",
        "        # Crear tabla con índices\n",
        "        create_table_query = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS clientes_procesados (\n",
        "            codigo_usuario TEXT,\n",
        "            nombre TEXT,\n",
        "            direccion TEXT,\n",
        "            telefono TEXT,\n",
        "            correo_electronico TEXT,\n",
        "            fecha_de_alquiler TEXT,\n",
        "            fecha_de_entrega TEXT,\n",
        "            nombre_de_la_pelicula_video TEXT,\n",
        "            formato TEXT,\n",
        "            duracion_alquiler_dias INTEGER,\n",
        "            PRIMARY KEY (codigo_usuario, fecha_de_alquiler)\n",
        "        );\n",
        "        CREATE INDEX IF NOT EXISTS idx_formato ON clientes_procesados (formato);\n",
        "        CREATE INDEX IF NOT EXISTS idx_fecha_alquiler ON clientes_procesados (fecha_de_alquiler);\n",
        "        \"\"\"\n",
        "        conn.executescript(create_table_query)\n",
        "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "        conn.commit()\n",
        "        print(f\"Datos cargados en SQLite: {db_name}.{table_name} ({len(df)} filas)\")\n",
        "        conn.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error al cargar en SQLite: {e}\")\n",
        "\n",
        "# Carga en archivo Parquet\n",
        "def cargar_a_parquet(df, archivo_parquet='clientes_procesados.parquet'):\n",
        "    print(\"Cargando datos a archivo Parquet...\")\n",
        "    try:\n",
        "        df.to_parquet(archivo_parquet, engine='pyarrow', compression='snappy', index=False)\n",
        "        print(f\"Datos guardados en archivo Parquet: {archivo_parquet} ({len(df)} filas)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al guardar en Parquet: {e}\")\n",
        "\n",
        "# Ejemplo de lectura con Spark\n",
        "def leer_parquet_con_spark(archivo_parquet='clientes_procesados.parquet'):\n",
        "    print(\"Leyendo archivo Parquet con Spark...\")\n",
        "    try:\n",
        "        spark = SparkSession.builder.appName(\"LecturaParquet\").getOrCreate()\n",
        "        df_spark = spark.read.parquet(archivo_parquet)\n",
        "        print(\"Primeras 5 filas del archivo Parquet:\")\n",
        "        df_spark.show(5)\n",
        "        spark.stop()\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer con Spark: {e}\")\n",
        "\n",
        "# Función principal\n",
        "def cargar_datos_multiples(ruta_archivo):\n",
        "    df = cargar_y_preprocesar_datos(ruta_archivo)\n",
        "    if df is None:\n",
        "        print(\"Proceso abortado debido a fallo en la carga.\")\n",
        "        return\n",
        "\n",
        "    # Cargar a cada sistema\n",
        "    cargar_a_mongodb(df)\n",
        "    cargar_a_sqlite(df)\n",
        "    cargar_a_parquet(df)\n",
        "    leer_parquet_con_spark()  # Demostración de lectura con Spark\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ruta_archivo = \"Clientes.csv\"\n",
        "    cargar_datos_multiples(ruta_archivo)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
